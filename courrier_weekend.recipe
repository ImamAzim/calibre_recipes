#!/usr/bin/env python
# vim:fileencoding=utf-8

from calibre.web.feeds.news import BasicNewsRecipe
import re
import datetime

import dateutil.parser
from bs4 import BeautifulSoup

class AdvancedUserRecipe1667902828(BasicNewsRecipe):
    title          = 'CourrierWeekend'
    language = 'fr'
    base_url = "https://www.courrierinternational.com"
    today = datetime.date.today()
    since_last_saturday = (today.weekday() - 5)%7
    last_saturday = today - datetime.timedelta(days=since_last_saturday)
    pub_day_iso = last_saturday.isoformat()
    index_url = f'{base_url}/weekend/{pub_day_iso}/1'
    no_stylesheets = True
    auto_cleanup   = False
    max_articles_per_feed = 100

    keep_only_tags = [
        dict(name='div', attrs={'class': 'article-heading'}),
        dict(name='p', attrs={'class': 'article-lede'}),
        dict(name='div', attrs={'class': 'article-metas'}),
        dict(name='div', attrs={'class': 'article-content'}),
        dict(name='p', attrs={'class': 'article-authors'}),
        dict(name='div', attrs={'class': 'article-box-source'}),
    ]
    remove_tags = [
        dict(name='div', attrs={'class': 'article-tools'}),
        dict(name='div', attrs={'class': 'tools-list'}),
        dict(name='div', attrs={'class': 'article-readmore'}),
        dict(name='div', attrs={'class': 'tags-list'}),
        dict(name='div', attrs={'class': 'tags-list'}),
        dict(name='a', attrs={'class': 'source-link'}),
        dict(name='p', attrs={'class': 'article-vo'}),
        dict(name='div', attrs={'data-mobile': 'true'}),
        dict(name='section', attrs={'class': 'ci-services services-left'}),
    ]
    remove_attributes = [
            'loading',
            ]

    needs_subscription = True
    login_url = f'{base_url}/login'

    def get_browser(self):
        def is_form_login(form):
            return "id" in form.attrs and form.attrs['id'] == "user-login-form"
        br = BasicNewsRecipe.get_browser(self)
        if self.username:
            br.open(self.login_url)
            br.select_form(predicate=is_form_login)
            br['name'] = self.username
            br['pass'] = self.password
            br.submit()
        return br

    def parse_index(self):
        soup = self.index_to_soup(self.index_url)
        articles = list()
        for link in soup.find_all('a'):
            href = link.get('href')
            if 'article' in href:
                url = self.base_url + href
                title = href.replace('-', ' ').split('/')[-1].split('_')[-2]
                date = self.last_saturday.isoformat()
                article = dict(
                        title=title,
                        url=url,
                        date=date,
                        )
                articles.append(article)
        feeds = [('Articles', articles)]
        return feeds
